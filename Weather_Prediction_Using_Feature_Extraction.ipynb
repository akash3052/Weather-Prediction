{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weather_Prediction_Using Feature Extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAu8W72DMYDa"
      },
      "source": [
        "**Project Topic:** Weather Condition Prediction from Image\n",
        "\n",
        "**_Abstract:_** Basically, problem is to recognise or predict weather condition(air condition) in given picture(image data) . In this notebook , I am predicting weather condition by using extracted useful features from image and advanced methods/algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewnn1aiOJt0a"
      },
      "source": [
        "!ln -s /content/drive/My\\ Drive/ mydrive      "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVXitpzDK2a2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D80fyTXjBDqs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QKLZ7cRBD0w"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "import seaborn as sns\n",
        "from keras import optimizers, Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten,Dropout,Activation\n",
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1gFeOPVNqQ7"
      },
      "source": [
        "**Assigning Images and Labels for all classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5MX7tzIBOY7"
      },
      "source": [
        "image_paths=[]\n",
        "labels=[]"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvatLZRlBRVM"
      },
      "source": [
        "cnt=0\n",
        "flag=0\n",
        "path_of_class0=\"/content/mydrive/new_weather_train_data/0\"\n",
        "for r, d, f in os.walk(path_of_class0):\n",
        "    for file in f:\n",
        "        image_paths.append(os.path.join(r, file))\n",
        "        labels.append(0)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PvFFmJnBUb4",
        "outputId": "e3693b0c-d8ba-4482-e6f6-febfac08c964"
      },
      "source": [
        "print(len(image_paths))\n",
        "print(len(labels))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xL7Ii6dBXqE"
      },
      "source": [
        "cnt=0\n",
        "flag=0\n",
        "path_of_class1=\"/content/mydrive/new_weather_train_data/1\"\n",
        "for r, d, f in os.walk(path_of_class1):\n",
        "    for file in f:\n",
        "        image_paths.append(os.path.join(r, file))\n",
        "        labels.append(1)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-2keFU4BZpA",
        "outputId": "10ff1772-4693-4abe-adda-b0461a871e76"
      },
      "source": [
        "print(len(image_paths))\n",
        "print(len(labels))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpx6db2GBnmJ"
      },
      "source": [
        "cnt=0\n",
        "flag=0\n",
        "path_of_class2=\"/content/mydrive/new_weather_train_data/2\"\n",
        "for r, d, f in os.walk(path_of_class2):\n",
        "    for file in f:\n",
        "        image_paths.append(os.path.join(r, file))\n",
        "        labels.append(2)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boo6lA3DBpEQ",
        "outputId": "7bfbe688-56da-44ad-8b75-7e5072013082"
      },
      "source": [
        "print(len(image_paths))\n",
        "print(len(labels))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500\n",
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8saW3o9pBbki"
      },
      "source": [
        "cnt=0\n",
        "flag=0\n",
        "path_of_class3=\"/content/mydrive/new_weather_train_data/3\"\n",
        "for r, d, f in os.walk(path_of_class3):\n",
        "    for file in f:\n",
        "        image_paths.append(os.path.join(r, file))\n",
        "        labels.append(3)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_voYtWJKBdvI",
        "outputId": "c5283c87-ebdb-4b13-bd8e-192c5ee9c88e"
      },
      "source": [
        "print(len(image_paths))\n",
        "print(len(labels))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n",
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J7eSTKYBgYU"
      },
      "source": [
        "cnt=0\n",
        "flag=0\n",
        "path_of_class4=\"/content/mydrive/new_weather_train_data/4\"\n",
        "for r, d, f in os.walk(path_of_class4):\n",
        "    for file in f:\n",
        "        image_paths.append(os.path.join(r, file))\n",
        "        labels.append(4)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIjv7yqEBiMl",
        "outputId": "31ce8b96-b532-46d2-d29a-7c5782eb486a"
      },
      "source": [
        "print(len(image_paths))\n",
        "print(len(labels))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2500\n",
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NHj2rJ1B7Ai"
      },
      "source": [
        ""
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeETj0vAN_4-"
      },
      "source": [
        "**Fuctions for feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIB2bnnEB7n0"
      },
      "source": [
        "def contrast(rgb_image):\n",
        "    d_primes = []\n",
        "    b_primes = []\n",
        "\n",
        "    for i in np.arange(len(rgb_image)):\n",
        "        for j in np.arange(len(rgb_image[i])):\n",
        "            d_primes.append(min((rgb_image[i][j][0],rgb_image[i][j][1],rgb_image[i][j][2])))\n",
        "            b_primes.append(max((rgb_image[i][j][0], rgb_image[i][j][1], rgb_image[i][j][2])))\n",
        "\n",
        "    max_b = max(b_primes)\n",
        "    avg_d = sum(d_primes) / len(d_primes)\n",
        "    avg_b = sum(b_primes) / len(b_primes)\n",
        "    contrast = avg_d - avg_b\n",
        "    normalized_contrast = (contrast) / (255)\n",
        "\n",
        "    return (normalized_contrast,contrast,max_b,avg_d,avg_b)\n",
        "\n",
        "def brightness(rgb_image):\n",
        "    brightness_list = []\n",
        "    for i in np.arange(len(rgb_image)):\n",
        "        for j in np.arange(len(rgb_image[i])):\n",
        "            pixel_r = rgb_image[i][j][0]\n",
        "            pixel_g = rgb_image[i][j][1]\n",
        "            pixel_b = rgb_image[i][j][2]\n",
        "\n",
        "            brightness = (0.299 * pixel_r) + (0.587 * pixel_g) + (0.114 * pixel_b)\n",
        "            brightness_list.append(brightness)\n",
        "\n",
        "    brightness = sum(brightness_list)/len(brightness_list)\n",
        "    normalized_brightness = (brightness) / (255)\n",
        "\n",
        "    return normalized_brightness\n",
        "\n",
        "\n",
        "def haze(contrast,max_b,avg_d,avg_b,lamb=1/3):\n",
        "    A = (lamb * max_b) + ((1 - lamb) * avg_b)\n",
        "    x1 = (A - avg_d) / A\n",
        "    x2 = contrast / A\n",
        "\n",
        "    haze = math.exp((-0.5 * ((5.1 * x1) + (2.9 * x2))) + 0.2461) #normalized value\n",
        "\n",
        "    return haze\n",
        "\n",
        "\n",
        "def color_hist(rgb_image, numofbin = 256):\n",
        "    histR, bins = np.histogram(rgb_image[:, 0], np.arange(0, numofbin + 1), density=True)\n",
        "    histG, bins = np.histogram(rgb_image[:, 1], np.arange(0, numofbin + 1), density=True)\n",
        "    histB, bins = np.histogram(rgb_image[:, 2], np.arange(0, numofbin + 1), density=True)\n",
        "    hist = np.concatenate((histR, histG, histB), axis=0)\n",
        "    return hist\n",
        "\n",
        "def intensity_hist(rgb_image,white_threshold):\n",
        "    rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
        "    white_pixels = 0\n",
        "    black_pixels = 0\n",
        "    for i in np.arange(rgb_image.shape[0]):\n",
        "        for j in np.arange(rgb_image.shape[1]):\n",
        "            if (rgb_image.item(i, j) < white_threshold):\n",
        "                black_pixels += 1\n",
        "            else:\n",
        "                white_pixels += 1\n",
        "\n",
        "    return (white_pixels / (black_pixels + white_pixels))\n",
        "\n",
        "def sharpness(rgb_image):\n",
        "    image = cv2.cvtColor(rgb_image,cv2.COLOR_RGB2GRAY)  # to grayscale\n",
        "    array = np.asarray(image, dtype=np.int32)\n",
        "\n",
        "    dx = np.diff(array)[1:, :]  # remove the first row\n",
        "    dy = np.diff(array, axis=0)[:, 1:]  # remove the first column\n",
        "    dnorm = np.sqrt(dx ** 2 + dy ** 2)\n",
        "\n",
        "    sharpness = np.average(dnorm)\n",
        "    normalized_sharpness = sharpness / 40\n",
        "\n",
        "    return normalized_sharpness"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnYaQLjQOWCi"
      },
      "source": [
        "**Taking each image and extracting features from it and appending it in training data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FWbFwMgB9B5"
      },
      "source": [
        "x_data_gray=[]\n",
        "contrast_array=[]\n",
        "brightness_array=[]\n",
        "haze_array=[]\n",
        "color_hist_array=[]\n",
        "intensity_hist_array=[]\n",
        "sharpness_array=[]\n",
        "\n",
        "cnt=0\n",
        "for path in image_paths:\n",
        "    img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "\n",
        "    (norm_cont,c,max_b,avg_d,avg_b) =contrast(img)\n",
        "    contrast_array.append(norm_cont)\n",
        "\n",
        "    brightness_value=brightness(img)\n",
        "    brightness_array.append(brightness_value)\n",
        "\n",
        "    haze_value=haze(c,max_b,avg_d,avg_b)\n",
        "    haze_array.append(haze_value)\n",
        "\n",
        "    color_hist_value=color_hist(img)\n",
        "    color_hist_array.append(color_hist_value)\n",
        "\n",
        "    intensity_hist_value=intensity_hist(img,175)\n",
        "    intensity_hist_array.append(intensity_hist_value)\n",
        "\n",
        "    sharpness_value=sharpness(img)\n",
        "    sharpness_array.append(sharpness_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vq8RUB-OkwB"
      },
      "source": [
        "**Converting each feature in numpy array so that we can concatenate it later.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUm5YSijC7f9"
      },
      "source": [
        "contrast_nparray=np.array(contrast_array)\n",
        "brightness_nparray=np.array(brightness_array)\n",
        "haze_nparray=np.array(haze_array)\n",
        "color_hist_nparray=np.array(color_hist_array)\n",
        "intensity_hist_nparray=np.array(intensity_hist_array)\n",
        "sharpness_nparray=np.array(sharpness_array)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyl1w8ISkzm2",
        "outputId": "b9d50330-ef47-4e6c-c216-74d5bb4473f7"
      },
      "source": [
        "print(contrast_nparray.shape)\n",
        "print(brightness_nparray.shape)\n",
        "print(haze_nparray.shape)\n",
        "print(color_hist_nparray.shape)\n",
        "print(intensity_hist_nparray.shape)\n",
        "print(sharpness_nparray.shape)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500,)\n",
            "(2500,)\n",
            "(2500,)\n",
            "(2500, 768)\n",
            "(2500,)\n",
            "(2500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdbe13WDmOax",
        "outputId": "7877085a-c105-4fd5-92dc-fc45c6553faf"
      },
      "source": [
        "contrast_nparray.reshape(-1,1)\n",
        "print(contrast_nparray.shape)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUZE2eAfO2AB"
      },
      "source": [
        "**Concatenating all the extracted features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZgaaVwyCne2",
        "outputId": "b63d44c6-1c7a-4610-c8cb-d8a474f9ba11"
      },
      "source": [
        "x_data=np.concatenate((contrast_nparray[:,None],brightness_nparray[:,None],haze_nparray[:,None],color_hist_nparray,intensity_hist_nparray[:,None],sharpness_nparray[:,None]),axis=1)\n",
        "print(x_data.shape)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500, 773)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp1fRik3p0cP",
        "outputId": "1e20d8c4-bcf5-4ee9-de32-bcc60a8234cc"
      },
      "source": [
        "y_data=np.array(labels)\n",
        "y_data=y_data.reshape(-1,1)\n",
        "print(y_data.shape)\n",
        "y_data_reshaped=y_data.reshape(-1,1)\n",
        "print(y_data_reshaped.shape)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500, 1)\n",
            "(2500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFoIMVvXPA_V"
      },
      "source": [
        "**Splitting the data into training and testing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Yg2HUKp0fF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data_reshaped, test_size=0.2, random_state=42)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sReIPYn9p0j0",
        "outputId": "89ef1de2-7897-4dca-aee3-821468f6f7bd"
      },
      "source": [
        "print(\"x_train shape : \",x_train.shape)\n",
        "print(\"x_test shape  : \",x_test.shape)\n",
        "print(\"y_train shape : \",y_train.shape)\n",
        "print(\"y_test shape  : \",y_test.shape)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape :  (2000, 773)\n",
            "x_test shape  :  (500, 773)\n",
            "y_train shape :  (2000, 1)\n",
            "y_test shape  :  (500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc-QqabOPHRD"
      },
      "source": [
        "**Applying SVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jvSUzB8p0on",
        "outputId": "17978145-2644-4669-cf36-cc98dc3ac3ff"
      },
      "source": [
        "# Applying SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
              "                     random_state=None, shrinking=True, tol=0.001,\n",
              "                     verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfFxN-hMPNF_"
      },
      "source": [
        "**Evaluation Metrics**<br><br>\n",
        "**Precision** : The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
        "<br>\n",
        "<br>\n",
        "**Recall** : The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
        "<br> \n",
        "<br>\n",
        "**F1 Score**: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. <br>\n",
        "The formula for the F1 score is:\n",
        "\n",
        "F1 = 2 * (precision * recall) / (precision + recall)\n",
        "<br>\n",
        "<br>\n",
        "**Accuracy** : Accuracy is the measurement used to determine which model is best at identifying relationships and patterns between variables in a dataset based on the input, or training, data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Bqs92Qp0vv"
      },
      "source": [
        "y_pred= clf.predict(x_test)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tElO-LWNp0yS",
        "outputId": "643e6186-43d0-4ee2-9f36-932aa94b5a31"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"accuracy :\",accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7FKO_mgp00t",
        "outputId": "ae55bdf5-513b-47a4-f1b2-b17d11e89c78"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(\"f1-score : \",end=\"\")\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "print(\"recall : \",recall_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "print(\"precision : \",end=\"\")\n",
        "precision_score(y_test, y_pred, average='macro')\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1-score : 0.45121536890076214\n",
            "recall :  0.46064188822253344\n",
            "precision : "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45458176185209975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-MK-8kJp031"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDoyW2htp0tf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWZnVuDoPSdO"
      },
      "source": [
        "**Random Forests :** Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean/average prediction (regression) of the individual trees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp7RLrwnPndA"
      },
      "source": [
        "**Applying Random Forests**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw92xdD2p0rh"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(bootstrap=False,\n",
        "                            max_leaf_nodes=None,\n",
        "                            n_estimators=12,  # The number of trees in the forest\n",
        "                            min_weight_fraction_leaf=0.0,\n",
        "                            )"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV0u0nsNEvo4",
        "outputId": "c2fd4d52-8b55-4395-cd79-fdeb11497d13"
      },
      "source": [
        "rf.fit(x_train, y_train)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=12,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxEJmWxc3sHs"
      },
      "source": [
        "y_pred1=rf.predict(x_test)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkofsIjLPuf5"
      },
      "source": [
        "**Evaluation Metrics**<br><br>\n",
        "**Precision** : The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
        "<br>\n",
        "<br>\n",
        "**Recall** : The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
        "<br> \n",
        "<br>\n",
        "**F1 Score**: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. <br>\n",
        "The formula for the F1 score is:\n",
        "\n",
        "F1 = 2 * (precision * recall) / (precision + recall)\n",
        "<br>\n",
        "<br>\n",
        "**Accuracy** : Accuracy is the measurement used to determine which model is best at identifying relationships and patterns between variables in a dataset based on the input, or training, data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzU86zD53sKe",
        "outputId": "c95d2835-3f69-493c-efcc-1f557f2124b1"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"accuracy :\",accuracy_score(y_test, y_pred1))\n"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMFRV9VA3sNI",
        "outputId": "49e2d976-c4ba-442d-cb56-82fa5b6cc5ae"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "print(\"f1-score : \",end=\"\")\n",
        "print(f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "print(\"recall : \",recall_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "print(\"precision : \",end=\"\")\n",
        "precision_score(y_test, y_pred, average='macro')\n"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1-score : 0.45121536890076214\n",
            "recall :  0.46064188822253344\n",
            "precision : "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45458176185209975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-8V8tt13sSf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x473M-Hat5sV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}